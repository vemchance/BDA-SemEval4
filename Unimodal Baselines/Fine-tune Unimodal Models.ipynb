{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8a49a9-73ef-434f-bdc2-291c0a8078c9",
   "metadata": {},
   "source": [
    "Just another example notebook experimenting with finetuning different models (mainly BERT) on the datasets, including the supplemental data. Not really successful although fine-tuned BERT does a decent 62% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2caf062-56e4-41b3-ac26-42cb2b0f3349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ff6c3-c4de-4e4c-a56c-9918e9af6ced",
   "metadata": {},
   "source": [
    "# Binary Class Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d0c99-000f-4015-a3be-eb6d53f8cdff",
   "metadata": {},
   "source": [
    "## Data and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51d5e47d-0674-44ff-b3f9-21d807470e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r'X:\\PhD\\SemEval Task4\\Data\\annotations\\data\\subtask1\\train.json')\n",
    "df = df.applymap(str)\n",
    "\n",
    "val_df = pd.read_json(r'X:\\PhD\\SemEval Task4\\Data\\annotations\\data\\subtask1\\validation.json')\n",
    "val_df = val_df.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38a38fc0-e3e7-4850-ae29-179995e10d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "propagandistic = df.labels != '[]'\n",
    "non_propagandistic = df.labels == '[]'\n",
    "df.loc[propagandistic, 'labels'] = 1\n",
    "df.loc[non_propagandistic, 'labels'] = 0\n",
    "\n",
    "propagandistic = df.labels != '[]'\n",
    "non_propagandistic = df.labels == '[]'\n",
    "val_df.loc[propagandistic, 'labels'] = 1\n",
    "val_df.loc[non_propagandistic, 'labels'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b906f3-9e7f-48b6-b04d-437b04194562",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48e22373-ef38-4fb2-a12b-bba13759eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3195000-d7b9-4ca0-aa1a-1287cb3b7dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  375\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "\n",
    "for sent in df['text']:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a96f4-cb36-4a73-8838-9862870b6659",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19e303ab-5b37-42bb-8044-ce293bdbfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in df['text']:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0dc8b15f-4907-4a8f-a3c5-af6476af72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df['labels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c7fd198-86c3-4c96-b142-568690f46505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14a556-13a2-4d84-814e-86069323409c",
   "metadata": {},
   "source": [
    "## Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b702d67-b264-476d-acc2-fcf7076879e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "\n",
    "for text in val_df['text']:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e64598c5-fcf8-47c8-9bc8-8920a3420144",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_df['labels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c604770b-2365-41c3-9d92-0bffd5bcdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe8c3c-43fb-410e-8cc8-0db31e36127b",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d260ac4-5c04-47cb-8c34-eb2b2cf36d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73a30c38-5372-442f-9a24-c9ce68db6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                     \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89c0a8de-abc5-4fff-85a9-e3ffd86fd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goat\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9d71821-6f7c-4336-9184-b2f06b32283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66815bba-285a-4f7e-aad9-06b8efe586b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:15:46 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07a984-805d-4fe0-a14b-bb87cd3d142d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02b46e05-fcdc-4bf8-908e-42731eb4ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('X:\\\\PhD\\\\SemEval Task4\\\\Code\\\\Mock Coding\\\\fine tuned\\\\bert_model_subtask2b_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6985e05a-4d0d-4e61-ae41-0a10cb5a6675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35807</td>\n",
       "      <td>DONALD TRUMP: BARACK\\nOBAMA AND JOE BIDEN\\nWIL...</td>\n",
       "      <td>prop_meme_6570.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30562</td>\n",
       "      <td>00\\n10% FOR\\nTHE BIG GUY\\nNANCY'S\\nCUT\\n@ImMem...</td>\n",
       "      <td>prop_meme_8346.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44163</td>\n",
       "      <td>To much political posting online\\nthese days, ...</td>\n",
       "      <td>prop_meme_24378.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24224</td>\n",
       "      <td>I DON'T THINK\\nYOU UNDERSTOOD\\nWHAT I SAID.\\nY...</td>\n",
       "      <td>prop_meme_2594.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31611</td>\n",
       "      <td>ⒸSergey Mihailicenko/Anadolu Agency via Getty ...</td>\n",
       "      <td>prop_meme_7654.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>24014</td>\n",
       "      <td>Joe Biden\\nis transplanting\\nHundreds of thous...</td>\n",
       "      <td>prop_meme_4276.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>31283</td>\n",
       "      <td>THE INDEPENDENT REVIEW BROUGHT ON BY\\nREPUBLIC...</td>\n",
       "      <td>prop_meme_7494.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>34833</td>\n",
       "      <td>Longtime White House Photographer Pete\\nSouza ...</td>\n",
       "      <td>prop_meme_6217.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>23378</td>\n",
       "      <td>✔\\nThe last time I was here in 2017\\nCapitol p...</td>\n",
       "      <td>prop_meme_3748.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>32158</td>\n",
       "      <td>Please have the following\\ndocuments with you:...</td>\n",
       "      <td>prop_meme_8698.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "0     35807  DONALD TRUMP: BARACK\\nOBAMA AND JOE BIDEN\\nWIL...   \n",
       "1     30562  00\\n10% FOR\\nTHE BIG GUY\\nNANCY'S\\nCUT\\n@ImMem...   \n",
       "2     44163  To much political posting online\\nthese days, ...   \n",
       "3     24224  I DON'T THINK\\nYOU UNDERSTOOD\\nWHAT I SAID.\\nY...   \n",
       "4     31611  ⒸSergey Mihailicenko/Anadolu Agency via Getty ...   \n",
       "...     ...                                                ...   \n",
       "1195  24014  Joe Biden\\nis transplanting\\nHundreds of thous...   \n",
       "1196  31283  THE INDEPENDENT REVIEW BROUGHT ON BY\\nREPUBLIC...   \n",
       "1197  34833  Longtime White House Photographer Pete\\nSouza ...   \n",
       "1198  23378  ✔\\nThe last time I was here in 2017\\nCapitol p...   \n",
       "1199  32158  Please have the following\\ndocuments with you:...   \n",
       "\n",
       "                    image  label  \n",
       "0      prop_meme_6570.png      1  \n",
       "1      prop_meme_8346.png      1  \n",
       "2     prop_meme_24378.png      0  \n",
       "3      prop_meme_2594.png      1  \n",
       "4      prop_meme_7654.png      1  \n",
       "...                   ...    ...  \n",
       "1195   prop_meme_4276.png      1  \n",
       "1196   prop_meme_7494.png      1  \n",
       "1197   prop_meme_6217.png      1  \n",
       "1198   prop_meme_3748.png      1  \n",
       "1199   prop_meme_8698.png      1  \n",
       "\n",
       "[1200 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r'X:\\PhD\\SemEval Task4\\Data\\annotations\\data\\subtask2b\\train.json')\n",
    "df = df.applymap(str)\n",
    "\n",
    "# binary so can convert\n",
    "def encode_df(dataframe, column):\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    dataframe[column] = le.fit_transform(dataframe[column])\n",
    "    return dataframe\n",
    "\n",
    "encode_df(df, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbefb992-a54e-429b-95ea-694aa25ddb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goat\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "for meme in df['text']:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        meme,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 512,\n",
    "                        truncation = True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9a5893b-603e-406b-85eb-c4376b1e9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks)\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9703fee5-6ca6-4bf4-a4ea-7c4ba723ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "            \n",
    "            predictions.extend(list(pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d738b388-3ffb-498b-be02-0ef427d09ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output = pd.DataFrame()\n",
    "# df_output['id'] = df['id']\n",
    "# df_output['label'] = df['label']\n",
    "# df_output['prediction'] =predictions\n",
    "# df_output.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f78c9d-d4a5-4b08-9301-47ba271fac19",
   "metadata": {},
   "source": [
    "# Binary Class Problem - Finetune on PTC\n",
    "Terrible experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe4e4557-3a65-4dc3-b62b-1f1a3fb19777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CreateLabelsDataframeSLC:\n",
    "    \"\"\"\n",
    "    Class to create the labels of the SLC dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_labels(path: str):\n",
    "        '''\n",
    "        This helper function will create a dataframe with the labels of the dataset.\n",
    "        It will be then called from the createdataframeslc.py.\n",
    "\n",
    "        :type: path: str\n",
    "        :return: Pandas dataframe\n",
    "        '''\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for dirs, subdir, files in os.walk(path):  # Go through the directory with the files\n",
    "            for file in files:\n",
    "                filepath = dirs + '/' + file\n",
    "                with open(filepath, 'r') as single_file:\n",
    "                    # loop through all lines using f.readlines() method\n",
    "                    for line in single_file.readlines():\n",
    "                        line = line.strip().split('\\t')\n",
    "                        # print(line)\n",
    "                        data.append(line)\n",
    "\n",
    "        dataframe = pd.DataFrame(data, columns=['article_id', 'technique',\n",
    "                                                'start', 'end'])\n",
    "        # print(df)  # Debug\n",
    "        return dataframe\n",
    "\n",
    "path = r'X:\\PhD\\SemEval Task4\\Supplemental Data\\SemEval 2020 Task 11 PTC Corpus\\datasets-v2\\datasets\\train-labels-task2-technique-classification'\n",
    "load_labels = CreateLabelsDataframeSLC.load_labels(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2bf2cece-3dca-464f-ab3c-3ea14e82659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>technique</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "      <td>265</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "      <td>1795</td>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>149</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>1069</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111111</td>\n",
       "      <td>Appeal_to_fear-prejudice</td>\n",
       "      <td>1334</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>999001970</td>\n",
       "      <td>Slogans</td>\n",
       "      <td>191</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>999001970</td>\n",
       "      <td>Exaggeration,Minimisation</td>\n",
       "      <td>1043</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>999001970</td>\n",
       "      <td>Name_Calling,Labeling</td>\n",
       "      <td>1164</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>999001970</td>\n",
       "      <td>Exaggeration,Minimisation</td>\n",
       "      <td>1607</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>999001970</td>\n",
       "      <td>Exaggeration,Minimisation</td>\n",
       "      <td>2611</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id                  technique start   end\n",
       "0     111111111        Appeal_to_Authority   265   323\n",
       "1     111111111        Appeal_to_Authority  1795  1935\n",
       "2     111111111                      Doubt   149   157\n",
       "3     111111111                 Repetition  1069  1091\n",
       "4     111111111   Appeal_to_fear-prejudice  1334  1462\n",
       "...         ...                        ...   ...   ...\n",
       "6124  999001970                    Slogans   191   213\n",
       "6125  999001970  Exaggeration,Minimisation  1043  1148\n",
       "6126  999001970      Name_Calling,Labeling  1164  1183\n",
       "6127  999001970  Exaggeration,Minimisation  1607  1674\n",
       "6128  999001970  Exaggeration,Minimisation  2611  2651\n",
       "\n",
       "[6129 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5055f5e-b2bc-476d-9006-dc133a6e4e52",
   "metadata": {},
   "source": [
    "Handy pickle file. Credit: https://github.com/marcogdepinto/PropagandaDetection/blob/master/pickled/train_set_FLC.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4fcedfe-6741-447d-904b-ee80fbe10766",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'X:\\PhD\\SemEval Task4\\Supplemental Data\\SemEval 2020 Task 11 PTC Corpus\\train_set_SLC.pkl'\n",
    "df = pd.read_pickle(path)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1a561310-82fd-49f7-b417-ae0c6f343d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>line</th>\n",
       "      <th>is_propaganda</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761874505</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Ex-Sailor Pardoned By Trump Says He’s SUING O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761874505</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[A former Navy sailor, who is one of five peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>761874505</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[Kristian Saucier, who served a year in federa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>761874505</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[Saucier said that he realizes he had erred in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>761874505</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[He has also lashed out at Obama officials, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16960</th>\n",
       "      <td>694356862</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>[As the U.S.-led coalition continues to drive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16961</th>\n",
       "      <td>694356862</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>[National Security Adviser H.R.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16962</th>\n",
       "      <td>694356862</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>[McMaster said that the “so called liberation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16963</th>\n",
       "      <td>694356862</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>[Whether the Trump administration follows thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>694356862</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>[In the meantime, Israel will have to deal wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id  line  is_propaganda  \\\n",
       "0      761874505     1              0   \n",
       "2      761874505     3              0   \n",
       "3      761874505     4              0   \n",
       "4      761874505     5              0   \n",
       "5      761874505     6              0   \n",
       "...          ...   ...            ...   \n",
       "16960  694356862    29              0   \n",
       "16961  694356862    30              0   \n",
       "16962  694356862    31              1   \n",
       "16963  694356862    32              1   \n",
       "16964  694356862    33              0   \n",
       "\n",
       "                                                sentence  \n",
       "0      [Ex-Sailor Pardoned By Trump Says He’s SUING O...  \n",
       "2      [A former Navy sailor, who is one of five peop...  \n",
       "3      [Kristian Saucier, who served a year in federa...  \n",
       "4      [Saucier said that he realizes he had erred in...  \n",
       "5      [He has also lashed out at Obama officials, sa...  \n",
       "...                                                  ...  \n",
       "16960  [As the U.S.-led coalition continues to drive ...  \n",
       "16961                   [National Security Adviser H.R.]  \n",
       "16962  [McMaster said that the “so called liberation ...  \n",
       "16963  [Whether the Trump administration follows thro...  \n",
       "16964  [In the meantime, Israel will have to deal wit...  \n",
       "\n",
       "[16297 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df(df, 'is_propaganda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9b9cf9c-f0dc-4383-adbc-3017ffaaebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in df['sentence']:\n",
    "   \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 512,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "58e149c7-745a-41a9-8220-bd434c0302b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df['is_propaganda'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "367440d2-7818-4c82-a49f-100910ac5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c5026-d571-4845-9191-d72063a334ef",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f0c26ef-d71f-48ff-8f42-0989c2119186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                     \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b243dcae-6847-438d-ae98-fd9abc095adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 1:13:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 1:12:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 1:12:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 1:12:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 1:13:20\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "\n",
      "Training complete!\n",
      "Total training took 16:59:44 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
