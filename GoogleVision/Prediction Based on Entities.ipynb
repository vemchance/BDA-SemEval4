{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d07ce66-fcb7-4261-a689-980435be096b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3294e401-6967-4366-94ff-f190ed648ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, MulticlassF1Score\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473899d5-ffd0-42a6-a080-581bd2e9eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_subtask2a_train = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2a\\\\train.json')\n",
    "anno_subtask2a_train['subset'] = 'train'\n",
    "anno_subtask2a_val = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2a\\\\validation.json')\n",
    "anno_subtask2a_val['subset'] = 'val'\n",
    "anno_subtask2a_dev = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2a\\\\dev_unlabeled.json')\n",
    "\n",
    "anno_subtask2a_combined = pd.concat([anno_subtask2a_train, anno_subtask2a_val])\n",
    "\n",
    "anno_subtask2b_train = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2b\\\\train.json')\n",
    "anno_subtask2b_train['subset'] = 'train'\n",
    "anno_subtask2b_val = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2b\\\\val.json')\n",
    "anno_subtask2b_val['subset'] = 'val'\n",
    "anno_subtask2b_dev = pd.read_json('X:\\\\PhD\\\\SemEval Task4\\\\Data\\\\annotations\\\\data\\\\subtask2b\\\\dev_unlabeled.json')\n",
    "\n",
    "anno_subtask2b_combined = pd.concat([anno_subtask2b_train, anno_subtask2b_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6546ae-5809-447e-a9be-1cda37869a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35807</td>\n",
       "      <td>DONALD TRUMP: BARACK\\nOBAMA AND JOE BIDEN\\nWIL...</td>\n",
       "      <td>prop_meme_6570.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>train</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30562</td>\n",
       "      <td>00\\n10% FOR\\nTHE BIG GUY\\nNANCY'S\\nCUT\\n@ImMem...</td>\n",
       "      <td>prop_meme_8346.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>train</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44163</td>\n",
       "      <td>To much political posting online\\nthese days, ...</td>\n",
       "      <td>prop_meme_24378.png</td>\n",
       "      <td>non_propagandistic</td>\n",
       "      <td>train</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24224</td>\n",
       "      <td>I DON'T THINK\\nYOU UNDERSTOOD\\nWHAT I SAID.\\nY...</td>\n",
       "      <td>prop_meme_2594.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>train</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31611</td>\n",
       "      <td>ⒸSergey Mihailicenko/Anadolu Agency via Getty ...</td>\n",
       "      <td>prop_meme_7654.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>train</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>44900</td>\n",
       "      <td>197\\nNazi ain't got no humanity\\nThey're the f...</td>\n",
       "      <td>prop_meme_19869.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>val</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>12635</td>\n",
       "      <td>HANG ONTHAVE\\nA MEME\\nFOR THIS\\n</td>\n",
       "      <td>prop_meme_641.png</td>\n",
       "      <td>non_propagandistic</td>\n",
       "      <td>val</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>12740</td>\n",
       "      <td>HE GAVE HIS BLOOD, SWEAT AND TEARS\\nFOR THE AM...</td>\n",
       "      <td>prop_meme_746.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>val</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>46086</td>\n",
       "      <td>BUT I WANTED NORTH\\nKOREA TO NUKE US\\nTO MAKE ...</td>\n",
       "      <td>prop_meme_18775.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>val</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>30279</td>\n",
       "      <td>AGENDA 21\\nDIY.DESPAIR.COM</td>\n",
       "      <td>prop_meme_5619.png</td>\n",
       "      <td>propagandistic</td>\n",
       "      <td>val</td>\n",
       "      <td>X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "0     35807  DONALD TRUMP: BARACK\\nOBAMA AND JOE BIDEN\\nWIL...   \n",
       "1     30562  00\\n10% FOR\\nTHE BIG GUY\\nNANCY'S\\nCUT\\n@ImMem...   \n",
       "2     44163  To much political posting online\\nthese days, ...   \n",
       "3     24224  I DON'T THINK\\nYOU UNDERSTOOD\\nWHAT I SAID.\\nY...   \n",
       "4     31611  ⒸSergey Mihailicenko/Anadolu Agency via Getty ...   \n",
       "...     ...                                                ...   \n",
       "1345  44900  197\\nNazi ain't got no humanity\\nThey're the f...   \n",
       "1346  12635                   HANG ONTHAVE\\nA MEME\\nFOR THIS\\n   \n",
       "1347  12740  HE GAVE HIS BLOOD, SWEAT AND TEARS\\nFOR THE AM...   \n",
       "1348  46086  BUT I WANTED NORTH\\nKOREA TO NUKE US\\nTO MAKE ...   \n",
       "1349  30279                         AGENDA 21\\nDIY.DESPAIR.COM   \n",
       "\n",
       "                    image               label subset  \\\n",
       "0      prop_meme_6570.png      propagandistic  train   \n",
       "1      prop_meme_8346.png      propagandistic  train   \n",
       "2     prop_meme_24378.png  non_propagandistic  train   \n",
       "3      prop_meme_2594.png      propagandistic  train   \n",
       "4      prop_meme_7654.png      propagandistic  train   \n",
       "...                   ...                 ...    ...   \n",
       "1345  prop_meme_19869.png      propagandistic    val   \n",
       "1346    prop_meme_641.png  non_propagandistic    val   \n",
       "1347    prop_meme_746.png      propagandistic    val   \n",
       "1348  prop_meme_18775.png      propagandistic    val   \n",
       "1349   prop_meme_5619.png      propagandistic    val   \n",
       "\n",
       "                                               filepath  \n",
       "0     X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...  \n",
       "1     X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...  \n",
       "2     X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...  \n",
       "3     X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...  \n",
       "4     X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\tra...  \n",
       "...                                                 ...  \n",
       "1345  X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...  \n",
       "1346  X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...  \n",
       "1347  X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...  \n",
       "1348  X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...  \n",
       "1349  X:\\PhD\\SemEval Task4\\Data\\subtask2b_images\\val...  \n",
       "\n",
       "[1350 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'X:\\PhD\\SemEval Task4\\Data\\subtask2a_images'\n",
    "images = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(path) for f in filenames]\n",
    "images_df = pd.DataFrame(images, columns=['filepath'])\n",
    "images_df['image'] = images_df['filepath'].str.split('\\\\').str[-1]\n",
    "\n",
    "subtask2a = pd.merge(anno_subtask2a_combined, images_df, on='image')\n",
    "\n",
    "path = r'X:\\PhD\\SemEval Task4\\Data\\subtask2b_images'\n",
    "images = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(path) for f in filenames]\n",
    "images_df = pd.DataFrame(images, columns=['filepath'])\n",
    "images_df['image'] = images_df['filepath'].str.split('\\\\').str[-1]\n",
    "\n",
    "subtask2b = pd.merge(anno_subtask2b_combined, images_df, on='image')\n",
    "\n",
    "# has a nan text field so replace it with an empty string\n",
    "subtask2b['text'] = subtask2b['text'].fillna(' ')\n",
    "subtask2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab6768-d7fe-4bc2-8769-78a6d4382266",
   "metadata": {},
   "source": [
    "## Merge the Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad3ada2e-98f9-4d64-8768-5b9e4703cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f = r'X:\\PhD\\SemEval Task4\\Code\\GoogleVision\\vision_face_detect.json'\n",
    "path_w = r'X:\\PhD\\SemEval Task4\\Code\\GoogleVision\\web_entities.json'\n",
    "\n",
    "with open(path_f) as f:\n",
    "    faces = json.load(f)\n",
    "\n",
    "with open(path_w) as f:\n",
    "    web_ents = json.load(f)\n",
    "\n",
    "# function for sorting the JSON file a bit more sensibly to work with\n",
    "# col is in the Response: e.g., webEntities, fullMatchingImages .etc, check the json\n",
    "\n",
    "def explode_frame(json_file, col):\n",
    "    df = pd.json_normalize(json_file)\n",
    "    df.set_index('Image ID', inplace=True)\n",
    "    return df['Response.' + col].explode().pipe(lambda x: pd.json_normalize(x).set_index(x.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378ef256-a55d-412e-9e7e-8b759b9e9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_ents = explode_frame(web_ents, 'webEntities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7bbe3fb-3c85-4ff5-9b1b-bd5a708f4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the labels, merge the frames\n",
    "labels = pd.concat([subtask2a[['id', 'image', 'labels']], subtask2b[['id', 'image', 'label']]])\n",
    "labels.rename(columns={'labels': '2a_label', 'label': '2b_label'}, inplace=True)\n",
    "web_ents = web_ents.merge(labels, left_on=web_ents.index, right_on='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2faa2da-b431-4492-bdbf-483d4638058a",
   "metadata": {},
   "source": [
    "# Subtask2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d9a7d60-6442-491f-b93d-4db28ac864f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = web_ents.dropna(subset='2b_label') # just changing it here \n",
    "df = df.drop(columns='2a_label')\n",
    "df = df.groupby('id').agg(list).reset_index()\n",
    "df['description'] = df['description'].apply(lambda x: list(set(x)))\n",
    "df['2b_label'] = [x for x in df['2b_label'].apply(lambda x: list(set(x)))]\n",
    "df['image'] = df['image'].apply(lambda x: list(set(x)))\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36116c87-f1a9-4851-8411-c82775fbe6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entityId</th>\n",
       "      <th>score</th>\n",
       "      <th>description</th>\n",
       "      <th>image</th>\n",
       "      <th>2b_label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015</td>\n",
       "      <td>['/m/06mg_j', '/m/01jddz', '/m/02jjt', '/m/052...</td>\n",
       "      <td>[0.65761805, 0.5491231, 0.5085392, 0.4730451, ...</td>\n",
       "      <td>['Convention', 'Musical ensemble', 'Concert', ...</td>\n",
       "      <td>['prop_meme_3.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10018</td>\n",
       "      <td>['/m/013s93', '/m/01zlzf', '/m/01n4qj', '/m/01...</td>\n",
       "      <td>[0.63, 0.43245, 0.416, 0.37267068, 0.3432773, ...</td>\n",
       "      <td>['Chicha', 'Journalist', 'Product', 'T-shirt',...</td>\n",
       "      <td>['prop_meme_6.png']</td>\n",
       "      <td>['propagandistic']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10257</td>\n",
       "      <td>['/m/07crc', '/m/051zk', '/t/280hgdwwmpmhj', '...</td>\n",
       "      <td>[1.08525, 0.97965, 0.738, 0.738, 0.7153, 0.704...</td>\n",
       "      <td>[nan, 'Choco Taco', 'Dessert tacos', 'Value me...</td>\n",
       "      <td>['prop_meme_245.png']</td>\n",
       "      <td>['propagandistic']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11736</td>\n",
       "      <td>['/g/11fljpmxv', '/g/120xp5nm', '/g/11q4gdbgt3...</td>\n",
       "      <td>[0.4142, 0.3957, 0.3118, 0.2946, 0.2853, 0.279...</td>\n",
       "      <td>['Ovulation Test', 'personal', 'important', 'O...</td>\n",
       "      <td>['prop_meme_269.png']</td>\n",
       "      <td>['propagandistic']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12345</td>\n",
       "      <td>['/g/11kkx451vq', '/g/11hgzk9flm', '/m/060d2',...</td>\n",
       "      <td>[0.71295, 0.597, 0.5965, 0.5184, 0.3457, 0.074...</td>\n",
       "      <td>[nan, 'The First Presidential Debate', 'First ...</td>\n",
       "      <td>['prop_meme_351.png']</td>\n",
       "      <td>['propagandistic']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>56209</td>\n",
       "      <td>['/g/11q3tk_3xv', '/m/04wpw', '/m/0bf3_n', '/g...</td>\n",
       "      <td>[0.7059, 0.4874, 0.44, 0.4048, 0.3842, 0.3197,...</td>\n",
       "      <td>['funny', 'CHWV-FM', 'Imgur', 'Culture', 'Funn...</td>\n",
       "      <td>['prop_meme_25022.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>56212</td>\n",
       "      <td>['/m/01b9xk', '/m/0bt9lr', '/m/01z5f', '/m/0bb...</td>\n",
       "      <td>[1.49805, 1.0897499, 0.7246549, 0.6803, 0.6009...</td>\n",
       "      <td>['Dog', 'Hot Dog', 'Canidae', 'Companion dog',...</td>\n",
       "      <td>['prop_meme_25025.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>56214</td>\n",
       "      <td>['/g/11h88gys_y', '/m/06nh1', '/m/01yrx', '/g/...</td>\n",
       "      <td>[1.62492, 0.75485855, 0.62432873, 0.5757, 0.49...</td>\n",
       "      <td>[nan, 'Cat', 'PCGamesN', 'Mammal', 'Blizzard E...</td>\n",
       "      <td>['prop_meme_25027.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>56216</td>\n",
       "      <td>['/m/02jz0l', '/m/01j2bj', '/m/0130jx', '/m/0d...</td>\n",
       "      <td>[0.7199, 0.5394, 0.5137, 0.4367, 0.4196, 0.407...</td>\n",
       "      <td>['Kitchen Tap', 'Shower', 'Funny meme', 'Bathr...</td>\n",
       "      <td>['prop_meme_25029.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>56218</td>\n",
       "      <td>['/m/0fngf', '/g/11q9s45c7g', '/m/0838f', '/m/...</td>\n",
       "      <td>[0.46754402, 0.4358, 0.33994943, 0.30544138, 0...</td>\n",
       "      <td>['Harare', 'Author', 'Water', 'Ecoregion', 'Fo...</td>\n",
       "      <td>['prop_meme_25031.png']</td>\n",
       "      <td>['non_propagandistic']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           entityId  \\\n",
       "0     10015  ['/m/06mg_j', '/m/01jddz', '/m/02jjt', '/m/052...   \n",
       "1     10018  ['/m/013s93', '/m/01zlzf', '/m/01n4qj', '/m/01...   \n",
       "2     10257  ['/m/07crc', '/m/051zk', '/t/280hgdwwmpmhj', '...   \n",
       "3     11736  ['/g/11fljpmxv', '/g/120xp5nm', '/g/11q4gdbgt3...   \n",
       "4     12345  ['/g/11kkx451vq', '/g/11hgzk9flm', '/m/060d2',...   \n",
       "...     ...                                                ...   \n",
       "1345  56209  ['/g/11q3tk_3xv', '/m/04wpw', '/m/0bf3_n', '/g...   \n",
       "1346  56212  ['/m/01b9xk', '/m/0bt9lr', '/m/01z5f', '/m/0bb...   \n",
       "1347  56214  ['/g/11h88gys_y', '/m/06nh1', '/m/01yrx', '/g/...   \n",
       "1348  56216  ['/m/02jz0l', '/m/01j2bj', '/m/0130jx', '/m/0d...   \n",
       "1349  56218  ['/m/0fngf', '/g/11q9s45c7g', '/m/0838f', '/m/...   \n",
       "\n",
       "                                                  score  \\\n",
       "0     [0.65761805, 0.5491231, 0.5085392, 0.4730451, ...   \n",
       "1     [0.63, 0.43245, 0.416, 0.37267068, 0.3432773, ...   \n",
       "2     [1.08525, 0.97965, 0.738, 0.738, 0.7153, 0.704...   \n",
       "3     [0.4142, 0.3957, 0.3118, 0.2946, 0.2853, 0.279...   \n",
       "4     [0.71295, 0.597, 0.5965, 0.5184, 0.3457, 0.074...   \n",
       "...                                                 ...   \n",
       "1345  [0.7059, 0.4874, 0.44, 0.4048, 0.3842, 0.3197,...   \n",
       "1346  [1.49805, 1.0897499, 0.7246549, 0.6803, 0.6009...   \n",
       "1347  [1.62492, 0.75485855, 0.62432873, 0.5757, 0.49...   \n",
       "1348  [0.7199, 0.5394, 0.5137, 0.4367, 0.4196, 0.407...   \n",
       "1349  [0.46754402, 0.4358, 0.33994943, 0.30544138, 0...   \n",
       "\n",
       "                                            description  \\\n",
       "0     ['Convention', 'Musical ensemble', 'Concert', ...   \n",
       "1     ['Chicha', 'Journalist', 'Product', 'T-shirt',...   \n",
       "2     [nan, 'Choco Taco', 'Dessert tacos', 'Value me...   \n",
       "3     ['Ovulation Test', 'personal', 'important', 'O...   \n",
       "4     [nan, 'The First Presidential Debate', 'First ...   \n",
       "...                                                 ...   \n",
       "1345  ['funny', 'CHWV-FM', 'Imgur', 'Culture', 'Funn...   \n",
       "1346  ['Dog', 'Hot Dog', 'Canidae', 'Companion dog',...   \n",
       "1347  [nan, 'Cat', 'PCGamesN', 'Mammal', 'Blizzard E...   \n",
       "1348  ['Kitchen Tap', 'Shower', 'Funny meme', 'Bathr...   \n",
       "1349  ['Harare', 'Author', 'Water', 'Ecoregion', 'Fo...   \n",
       "\n",
       "                        image                2b_label  labels  \n",
       "0         ['prop_meme_3.png']  ['non_propagandistic']       0  \n",
       "1         ['prop_meme_6.png']      ['propagandistic']       1  \n",
       "2       ['prop_meme_245.png']      ['propagandistic']       1  \n",
       "3       ['prop_meme_269.png']      ['propagandistic']       1  \n",
       "4       ['prop_meme_351.png']      ['propagandistic']       1  \n",
       "...                       ...                     ...     ...  \n",
       "1345  ['prop_meme_25022.png']  ['non_propagandistic']       0  \n",
       "1346  ['prop_meme_25025.png']  ['non_propagandistic']       0  \n",
       "1347  ['prop_meme_25027.png']  ['non_propagandistic']       0  \n",
       "1348  ['prop_meme_25029.png']  ['non_propagandistic']       0  \n",
       "1349  ['prop_meme_25031.png']  ['non_propagandistic']       0  \n",
       "\n",
       "[1350 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = df['2b_label'].replace({\"['non_propagandistic']\": 0, \"['propagandistic']\": 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09a62375-bd6f-4dc1-96da-8679eea9dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df['description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d2397-7c3d-4b42-8ccc-8b38279e9522",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ab029-43dd-4c2f-81a1-fa523b3117bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2869f6c0-e4e1-44c3-8e86-e84a339e6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e6f8d0de-aeb2-46ce-99b1-d5247feefbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = train['description'].tolist()\n",
    "descriptions_val = test['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bcbaf752-2e01-4247-acd2-99ddf16c8763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  128\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in descriptions:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4abf9ac1-9f1d-4bab-92b1-c8636b53cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in descriptions:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "\n",
    "for text in descriptions_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b0f430c-a218-4c34-86e4-5a470c6ed849",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(train['labels'].tolist())\n",
    "\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(test['labels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3337926d-3bbf-46a9-8516-6c4208fe6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9c5c5-2947-4ecc-9074-f2e6ba9f0d83",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c1728e1c-7053-490c-99e2-b644d78ea7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Goat\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                     \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dd35ded9-2e89-4611-bfec-5b76409a39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def f1_scorer(preds, labels):\n",
    "    f1 = BinaryF1Score()\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1(torch.tensor(pred_flat),  torch.tensor(labels_flat))\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765dbfb-bc8c-4952-8aff-2dc6a42b1b63",
   "metadata": {},
   "source": [
    "### Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0319a9ff-2e6c-49dc-bc61-8fcb8ef11ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.52\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.79\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.76\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.79\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:03:54 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14ccbb3f-eb48-4ab4-9bad-4153b232875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = f'Bert_entity_FT'\n",
    "save_path = 'X:\\\\PhD\\\\SemEval Task4\\\\Code\\\\1. Final Code\\\\NLP Finetuning\\\\models'\n",
    "\n",
    "torch.save(model, os.path.join(save_path, model_params+'.pth'))\n",
    "torch.save(model.state_dict(), os.path.join(save_path, model_params+'_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f30ae-b818-43ad-822b-a7bf7304000c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bb170dba-a725-4435-9f7a-93e0626af9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "F1: 0.83\n"
     ]
    }
   ],
   "source": [
    "# on the same validation set\n",
    "\n",
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "best_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "f1_score = 0\n",
    "   \n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "       \n",
    "    with torch.no_grad():        \n",
    "        output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "    loss = output.loss\n",
    "    total_eval_loss += loss.item()\n",
    "        \n",
    "    logits = output.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    f1_score += f1_scorer(logits, label_ids)\n",
    "   \n",
    "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "avg_f1 = f1_score / len(validation_dataloader)\n",
    "print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "print(\"F1: {0:.2f}\".format(avg_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "14307c01-f079-4cce-837b-9ff1338a38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pending dev set - need to extract labels again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d587ce-a0a4-49f1-9185-81ab8cc42c08",
   "metadata": {},
   "source": [
    "# Subtask2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4b7c6-d22d-40bc-9c28-b47e968e3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('labels')\n",
    "df['labels'].apply(lambda x: x if x else 'None')\n",
    "df.replace(lvl1_dict, inplace=True, regex=True)\n",
    "df = df.explode('labels')\n",
    "df.fillna('None', inplace=True)\n",
    "df = df.groupby('id').agg(list).reset_index()\n",
    "df['labels'] = df['labels'].apply(lambda x: list(set(x)))\n",
    "df['text'] = df['text'].str[0]\n",
    "df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "31e4a351-d015-4fe6-b073-7a0e91b56b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = anno_subtask2a_combined[['id', 'labels', 'image']]\n",
    "labels_df = labels_df.explode('labels')\n",
    "labels_df['labels'].apply(lambda x: x if x else 'None')\n",
    "labels_df.fillna('None', inplace=True)\n",
    "labels_df = labels_df.groupby('id').agg(list).reset_index()\n",
    "labels_df['labels'] = labels_df['labels'].apply(lambda x: list(set(x)))\n",
    "labels_df['image'] = labels_df['image'].str[0]\n",
    "labels_df['id'] = labels_df['id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b27cfb59-e02d-459b-bf12-87818174a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = web_ents.dropna(subset='2a_label') # just changing it here \n",
    "df = df.groupby('id').agg(list).reset_index()\n",
    "df['description'] = df['description'].apply(lambda x: list(set(x))).astype(str)\n",
    "df = df[['id', 'entityId', 'score', 'description']]\n",
    "df = pd.merge(df, labels_df, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9fb826d1-fa79-4ea9-be4a-10d33c30463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = df['labels'].values\n",
    "unique_labels = []\n",
    "\n",
    "for i in lab:\n",
    "    for x in i:\n",
    "        unique_labels.append(x)\n",
    "unique_labels = list(set(unique_labels))\n",
    "\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "ml = MultiLabelBinarizer()\n",
    "df['encoded_labels'] = ml.fit_transform(df['labels'])[:,1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d56ea3f3-55c7-4598-84d6-7594bcf0efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "descriptions = train['description'].tolist()\n",
    "descriptions_val = test['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9b2ec5e4-33af-48eb-b233-8622e1e50e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in descriptions:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "\n",
    "for text in descriptions_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          # default to 512\n",
    "                        pad_to_max_length = True,\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "79c42c4a-ec0e-422d-8310-916701ac2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(train['encoded_labels'].values.tolist())\n",
    "\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(test['encoded_labels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a47d5de5-42ab-4529-b216-c385bd561fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c514be5b-f423-4eaf-bb83-bbdf14e7e46c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new bert model, since we have more classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 22, # The number of output labels--2 for binary classification.                     \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False,\n",
    "    problem_type = \"multi_label_classification\" \n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e9102db4-163e-4361-b869-ebdd64795d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:38:18\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goat\\AppData\\Local\\Temp\\ipykernel_27140\\2117770405.py:10: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.00\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.19\n",
      "  Training epcoh took: 0:37:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:32:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:24:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:24:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.00\n",
      "\n",
      "Training complete!\n",
      "Total training took 2:53:48 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels) \n",
    "        loss = torch.nn.BCEWithLogitsLoss()(output.logits, b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].float().to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(output.logits, b_labels)\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ae58e3e1-0452-4086-990c-34ae9869af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = f'Bert_entity_FT_subtask2a'\n",
    "save_path = 'X:\\\\PhD\\\\SemEval Task4\\\\Code\\\\1. Final Code\\\\NLP Finetuning\\\\models'\n",
    "\n",
    "torch.save(model, os.path.join(save_path, model_params+'.pth'))\n",
    "torch.save(model.state_dict(), os.path.join(save_path, model_params+'_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f12da1-f03c-4b02-bb61-dce691aedefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def binary_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def f1_scorer(preds, labels):\n",
    "    f1 = BinaryF1Score()\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1(torch.tensor(pred_flat),  torch.tensor(labels_flat))\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "971c191b-a29b-4195-96f2-1a66f828e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.8942517042160034\n",
      "F1 Score = 0.26689666509628296\n",
      "Macro F1: 0.4740113914012909\n",
      "Weighted F1: 0.8543409109115601\n",
      "Macro Sample F1: 0.4740113914012909\n",
      "Micro Sample F1: 0.0\n",
      "tensor(0.2694)\n",
      "tensor([1.0000, 0.3333, 0.0000,  ..., 0.0000, 0.8000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# on the same validation set\n",
    "\n",
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "best_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "f1_score = 0\n",
    "\n",
    "fin_targets = []\n",
    "fin_outputs = []\n",
    "overall_acc = 0\n",
    "\n",
    "binaryacc = BinaryAccuracy().to(device)\n",
    "binaryf1 = BinaryF1Score().to(device)\n",
    "   \n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device).float()    \n",
    "       \n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(output.logits, b_labels)\n",
    "        logits = output.logits\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        targets = b_labels.to(device, dtype=torch.float)\n",
    "        logits = torch.sigmoid(logits)\n",
    "        overall_acc += binaryacc(logits, targets)\n",
    "        f1_score += binaryf1(logits, targets)\n",
    "        \n",
    "        fin_targets.extend(targets)\n",
    "        fin_outputs.extend(logits)\n",
    "\n",
    "\n",
    "print(f\"Accuracy Score = {overall_acc/len(validation_dataloader)}\")\n",
    "print(f\"F1 Score = {f1_score/len(validation_dataloader)}\")\n",
    "\n",
    "probs = [t.to('cpu').numpy() for t in fin_outputs]\n",
    "act = [t.to('cpu').numpy() for t in fin_targets]\n",
    "\n",
    "macrof1 = MulticlassF1Score(multidim_average='global', num_classes=num_classes, average='macro')\n",
    "print(f'Macro F1: {macrof1(torch.tensor(probs), torch.tensor(act))}')\n",
    "\n",
    "weightedf1 = MulticlassF1Score(multidim_average='global', num_classes=num_classes, average='weighted')\n",
    "print(f'Weighted F1: {weightedf1(torch.tensor(probs), torch.tensor(act))}')\n",
    "\n",
    "smacrof1 = MulticlassF1Score(multidim_average='samplewise', num_classes=num_classes, average='macro')\n",
    "print(f'Macro Sample F1: {macrof1(torch.tensor(probs), torch.tensor(act))}')\n",
    "\n",
    "smicrof1 = MulticlassF1Score(multidim_average='global', num_classes=num_classes, average='micro')\n",
    "print(f'Micro Sample F1: {smicrof1(torch.tensor(probs), torch.tensor(act))}')\n",
    "\n",
    "\n",
    "binaryf1 = BinaryF1Score(multidim_average='global')\n",
    "print(binaryf1(torch.tensor(probs), torch.tensor(act)))\n",
    "\n",
    "binaryf1 = BinaryF1Score(multidim_average='samplewise')\n",
    "print(binaryf1(torch.tensor(probs), torch.tensor(act)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a48e5-3599-4a41-ae95-b9ebf196d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sedat's hierarchial f1 code instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988420f0-2805-472e-b090-02d7843dcb81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
